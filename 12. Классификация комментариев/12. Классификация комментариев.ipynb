{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea2a4d3",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5ecab",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b144d",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcbd1c",
   "metadata": {},
   "source": [
    "Импортируем библиотеки, с которыми будем работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ea0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12018cb7",
   "metadata": {},
   "source": [
    "Сохраним данные в переменную `df` и посмотрим первые 10 строк датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6485c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f74d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37b7c6",
   "metadata": {},
   "source": [
    "Посмотрим общую информацию о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d071cb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0048ca",
   "metadata": {},
   "source": [
    "159 571 комментарий в нашем датасете, пропущенных значений нет.\n",
    "Проверим датасет на наличие дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4bf794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64508b3",
   "metadata": {},
   "source": [
    "Дубликатов в таблице нет.\n",
    "Напишем функцию очистки и лемматизации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b04a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = \" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
    "    return text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe06ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                          lemmatized_text  \n",
       "0       explanation why the edits made under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not trying to edit war it s...  \n",
       "3       more i can t make any real suggestion on impro...  \n",
       "4       you sir are my hero any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of asking when your vi...  \n",
       "159567  you should be ashamed of yourself that is a ho...  \n",
       "159568  spitzer umm there no actual article for prosti...  \n",
       "159569  and it look like it wa actually you who put on...  \n",
       "159570  and i really don t think you understand i came...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_text'] = df['text'].apply(clear_text)\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(lemmatize)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d43ba8",
   "metadata": {},
   "source": [
    "Удалим столбец с исходным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a806041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic                                    lemmatized_text\n",
       "0           0  explanation why the edits made under my userna...\n",
       "1           0  d aww he match this background colour i m seem...\n",
       "2           0  hey man i m really not trying to edit war it s...\n",
       "3           0  more i can t make any real suggestion on impro...\n",
       "4           0  you sir are my hero any chance you remember wh...\n",
       "...       ...                                                ...\n",
       "159566      0  and for the second time of asking when your vi...\n",
       "159567      0  you should be ashamed of yourself that is a ho...\n",
       "159568      0  spitzer umm there no actual article for prosti...\n",
       "159569      0  and it look like it wa actually you who put on...\n",
       "159570      0  and i really don t think you understand i came...\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['text'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e59c09",
   "metadata": {},
   "source": [
    "Проверим насколько сбалансированны данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d68e746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = df['toxic'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ece9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e09f53",
   "metadata": {},
   "source": [
    "Мы наблюдаем дисбаланс классов - негативные комментарии пишут в 10% случаев (отрицательный класс меньше положительного в 9 раз). При обучении моделей укажем параметр class_weight = None.\n",
    "\n",
    "Нам нужно построить модель для задачи классификации. Для этого разделим исходные данные на выборки - обучающую и тестовую в соотношении 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ec3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemmatized_text']\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3343011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=12345,\n",
    "                                                                            stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82d6c0",
   "metadata": {},
   "source": [
    "Преобразуем тексты в векторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47211135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем stop слова\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# создаем tf-idf\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stop_words)\n",
    "# обучаем и преобразуем обучающую выборку\n",
    "features_train = count_tf_idf.fit_transform(features_train.values.astype('U'))\n",
    "# преобразуем тестовую выборку\n",
    "features_test = count_tf_idf.transform(features_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115db28",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15774b8b",
   "metadata": {},
   "source": [
    "Мы предобработали данные - лемматизировали тексты, очистили от спецсимволов, удалили столбец с исходным текстом. Разделили данные на выборки, преобразовали тексты в векторы. Данные готовы к дальнейшей работе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e612b1c",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf8cb0",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5700ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели логистической регрессии: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Лучшая метрика F1 модели логистической регрессии: 0.762260673995937\n",
      "\n",
      "CPU times: total: 2.23 s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# инициализируем модель\n",
    "logreg = LogisticRegression(random_state = 12345, class_weight = None)\n",
    "\n",
    "# задаем параметры для модуля GridSearch\n",
    "param_grid = {'C': [10,100], 'solver':['liblinear', 'saga'], 'max_iter':[100,200]}\n",
    "\n",
    "# ищем лучшие параметры \n",
    "grid_logreg = GridSearchCV(logreg, param_grid, cv = 5, n_jobs = -1, scoring = 'f1')\n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "grid_logreg.fit(features_train, target_train)\n",
    "\n",
    "print('Лучшие параметры модели логистической регрессии:', grid_logreg.best_params_)\n",
    "print('Лучшая метрика F1 модели логистической регрессии:', grid_logreg.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e5193",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a9cf057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели решающего дерева: {'max_depth': 20, 'min_samples_split': 8}\n",
      "\n",
      "Лучшая метрика F1 модели решающего дерева: 0.6520058904902141\n",
      "\n",
      "CPU times: total: 10.2 s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "dt = DecisionTreeClassifier(random_state=12345, class_weight = None)\n",
    "\n",
    "# задаем параметры для модуля GridSearch \n",
    "param_grid = {\n",
    " 'max_depth': [1, 10, 20],\n",
    " 'min_samples_split': [8, 10, 12, 14, 16]\n",
    " }\n",
    "\n",
    "# ищем лучшие параметры \n",
    "grid_dt = GridSearchCV(estimator = dt, param_grid = param_grid, cv= 5, n_jobs = -1, scoring = 'f1') \n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "grid_dt.fit(features_train, target_train)\n",
    "\n",
    "# получаем лучшие параметры модели\n",
    "print('Лучшие параметры модели решающего дерева:', grid_dt.best_params_)\n",
    "print()\n",
    "\n",
    "# получаем лучшую оценку \n",
    "print('Лучшая метрика F1 модели решающего дерева:', grid_dt.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e0680",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d3d7866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели случайного леса: {'max_depth': 20, 'n_estimators': 100}\n",
      "\n",
      "Лучшая метрика F1 модели случайного леса: 0.0009237876657338217\n",
      "\n",
      "CPU times: total: 6.64 s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "rf = RandomForestClassifier(random_state=12345, class_weight = None)\n",
    "\n",
    "# задаем параметры для модуля GridSearch \n",
    "param_grid = {\n",
    " 'max_depth': [1, 10, 20],\n",
    " 'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# ищем лучшие параметры \n",
    "grid_rf = GridSearchCV(estimator = rf, param_grid = param_grid, cv= 5, n_jobs = -1, scoring='f1') \n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "grid_rf.fit(features_train, target_train)\n",
    "\n",
    "# получаем лучшие параметры модели\n",
    "print('Лучшие параметры модели случайного леса:', grid_rf.best_params_)\n",
    "print()\n",
    "\n",
    "# получаем лучшую оценку \n",
    "print('Лучшая метрика F1 модели случайного леса:', grid_rf.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c950669",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2c9d641",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Лучшие параметры модели LGBMC: {'max_depth': 20, 'n_estimators': 50}\n",
      "\n",
      "Лучшая метрика F1 модели LGBMC: 0.6899758463659129\n",
      "\n",
      "CPU times: total: 1min 17s\n",
      "Wall time: 7min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# инициализируем модель\n",
    "model = LGBMClassifier(random_state=12345, class_weight = None)\n",
    "\n",
    "# задаем параметры для модуля GridSearch ф\n",
    "param_grid = {'max_depth': range(10, 21, 5),\n",
    "              'n_estimators': range(10, 51, 10)}\n",
    "  \n",
    "# ищем лучшие параметры \n",
    "grid_model = GridSearchCV(estimator = model, param_grid = param_grid, cv= 5, n_jobs = -1, scoring= 'f1', verbose = 10) \n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "grid_model.fit(features_train, target_train)\n",
    "\n",
    "# получаем лучшие параметры модели\n",
    "print('Лучшие параметры модели LGBMC:', grid_model.best_params_)\n",
    "print()\n",
    "\n",
    "# получаем лучшую оценку\n",
    "print('Лучшая метрика F1 модели LGBMC:', grid_model.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24274cf3",
   "metadata": {},
   "source": [
    "Лучшее значение метрики F1 на обучающей выборке, соответствующее условиям задачи, получилось у модели логистической  \n",
    "регрессии - 0,76 с параметрами: 'C': 10, 'max_iter': 100, 'solver': 'liblinear'. Проверим работу моделей на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13f62b",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9424f7",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579f3b3",
   "metadata": {},
   "source": [
    "Лучшие параметры модели логистической регрессии: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6eb583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мера F1 модели линейной регрессии: 0.7776243093922652\n",
      "\n",
      "CPU times: total: 1.73 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "logreg = LogisticRegression(random_state=12345, class_weight = None, C=10, max_iter=100, solver='liblinear')\n",
    "\n",
    "# обучаем модель на тренировочной выборке\n",
    "logreg.fit(features_train, target_train)\n",
    "\n",
    "# находим предсказания на тестовой выборке\n",
    "predictions_logreg = logreg.predict(features_test)\n",
    "\n",
    "# оцениваем модель\n",
    "f1_logreg = f1_score(target_test, predictions_logreg)\n",
    "print('Мера F1 модели линейной регрессии:', f1_logreg)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bacbf5",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22358aed",
   "metadata": {},
   "source": [
    "Лучшие параметры модели решающего дерева: {'max_depth': 20, 'min_samples_split': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada722fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мера F1 модели решающего дерева: 0.6442477876106195\n",
      "\n",
      "CPU times: total: 9.44 s\n",
      "Wall time: 9.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "dt = DecisionTreeClassifier(random_state=12345, class_weight = None, max_depth = 20, min_samples_split = 8)\n",
    "\n",
    "# обучаем модель на тренировочной выборке\n",
    "dt.fit(features_train, target_train)\n",
    "\n",
    "# находим предсказания на тестовой выборке\n",
    "predictions_dt = dt.predict(features_test)\n",
    "\n",
    "# оцениваем модель\n",
    "f1_dt = f1_score(target_test, predictions_dt)\n",
    "print('Мера F1 модели решающего дерева:', f1_dt)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f24b6",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe840e",
   "metadata": {},
   "source": [
    "Лучшие параметры модели случайного леса: {'max_depth': 20, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae879c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мера F1 модели случайного леса: 0.0012319063751154912\n",
      "\n",
      "CPU times: total: 6.78 s\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "rf = RandomForestClassifier(random_state=12345, class_weight = None, max_depth = 20, n_estimators = 100)\n",
    "\n",
    "# обучаем модель на тренировочной выборке\n",
    "rf.fit(features_train, target_train)\n",
    "\n",
    "# находим предсказания на тестовой выборке\n",
    "predictions_rf = rf.predict(features_test)\n",
    "\n",
    "# оцениваем модель\n",
    "f1_rf = f1_score(target_test, predictions_rf)\n",
    "print('Мера F1 модели случайного леса:', f1_rf)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcbb88",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe79f4",
   "metadata": {},
   "source": [
    "Лучшие параметры модели LGBMC: {'max_depth': 20, 'n_estimators': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89cd7177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мера F1 для модели LGBMR: 0.6736015701668302\n",
      "\n",
      "CPU times: total: 1min 15s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# инициализируем модель\n",
    "model_LGBMC = LGBMClassifier(random_state=12345, class_weight = None, max_depth = 20, n_estimators = 50)\n",
    "\n",
    "# обучаем модель на тренировочной выборке\n",
    "model_LGBMC.fit(features_train, target_train)\n",
    "\n",
    "# находим предсказания на тестовой выборке\n",
    "predictions_LGBMC = model_LGBMC.predict(features_test)\n",
    "\n",
    "# оцениваем модель\n",
    "f1_LGBMC = f1_score(target_test, predictions_LGBMC)\n",
    "print('Мера F1 для модели LGBMR:', f1_LGBMC)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302c267",
   "metadata": {},
   "source": [
    "Лучшее значение метрики F1 на тестовой выборке получили для модели логистической регрессии - 0,7776. Худшее значение F1 у модели случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18569d77",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cd6f8",
   "metadata": {},
   "source": [
    "Объект нашего исследования - данные с разметкой о токсичности правок к описаниям товаров интернет-магазина \"Викишоп\".\n",
    "\n",
    "В ходе предобработки мы подготовили данные к моделированию:\n",
    "* лемматизировали тексты, \n",
    "* очистили от спецсимволов,\n",
    "* удалили столбец с исходным текстом, \n",
    "* преобразовали тексты в векторы. \n",
    "\n",
    "Для решения поставленной задачи мы разделили данные на две выборки:\n",
    "1. обучающую,\n",
    "2. тестовую.\n",
    "\n",
    "Обучили и проверили модели логистической регрессии, решающего дерева, случайного леса и модель градиентного бустинга LightGBMClassifier.\n",
    "\n",
    "По результатам обучения мы проверили все модели на тестовых выборках. Самое лучшее заначение метрики F1 0,7776 получили для модели логистической регресси на тестовой выборке.\n",
    "\n",
    "Подведём итог нашей работы - рекомендация для интернет-магазина \"Викишоп\":\n",
    "- чтобы искать токсичные комментарии и отправлять их на модерацию, рекомендуем использовать модель логистической регрессии с характеристиками:\n",
    "    * C=10, \n",
    "    * max_iter=100, \n",
    "    * solver='liblinear'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
